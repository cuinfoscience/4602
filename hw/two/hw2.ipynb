{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-4604/5604 HW2: Linear Classification \n",
    "\n",
    "### Solution by: *YOUR NAME* (and list any partners)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment overview\n",
    "\n",
    "News agencies, governments and corporations sometimes track social media during natural disasters to try to monitor unfolding events. But because no single person or group of people can read all available Twitter data, organizations may turn to natural language processing methods to try and understand what is happening as disasters unfold. \n",
    "\n",
    "While this approach is powerful, inferring events from NLP can be tricky. For instance, say a person [tweets](https://twitter.com/AnyOtherAnnaK/status/629195955506708480) that \"LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE.\" This tweet includes the word \"ablaze\", which may signal to a computer that there is an unfolding disaster. However, in this particular case, the person is speaking metaphorically. A simple computer system using keywords (e.g. ablaze) might be fooled into thinking the tweet is reporting an actual fire.\n",
    "\n",
    "In this assignment, you will predict if a given tweet actually refers to a natural disaster. This exercise is motivated by real-world disaster monitoring systems, and can help you to gain practice with supervised binary classification and natural language processing.\n",
    "\n",
    "__Note__: This dataset originally comes from [Kaggle](https://www.kaggle.com/c/nlp-getting-started/overview). But it has been modified for this problem set. Information about the data from this problem set that you find on Kaggle will almost certainly be wrong.\n",
    "\n",
    "### What to hand in\n",
    "\n",
    "You will submit the assignment on Canvas. Submit a single Jupyter notebook named `hw2lastname.ipynb`, where lastname is replaced with your last name. **Please also submit a PDF or HTML version of your notebook to Canvas**.\n",
    "\n",
    "Please clearly mark all deliverables. You are encouraged to create additional cells in whatever way makes the presentation more organized and easy to follow. You are allowed to import additional Python libraries.\n",
    "\n",
    "### Submission policies\n",
    "\n",
    "- **Collaboration:** You are allowed to work with one partner. You are still expected to write up your own solution. Each individual must turn in their own submission, and list your collaborators after your name.\n",
    "- **Late submissions:** Each student may use up to 5 late days over the semester. You have late days, not late hours. This means that if your submission is late by any amount of time past the deadline, then this will use up a late day. If it is late by any amount beyond 24 hours past the deadline, then this will use a second late, and so on. Once you have used up all late days, late assignments will be given at most 80% credit after one day and 60% credit after two days.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "In this assignment, you will experiment with perceptron and logistic regression in `sklearn`. Much of the code has already been written for you. We will use a class called `SGDClassifier` (which you should read about in the [sklearn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)), which  implements stochastic gradient descent (SGD) for a variety of loss functions, including both perceptron and logistic regression, so this will be a way to easily move between the two classifiers.\n",
    "\n",
    "The code below will load the datasets. There are two data collections: the \"training\" data, which contains the tweets that you will use for training the classifiers, and the \"testing\" data, which are tweets that you will use to measure the classifier accuracy. The test tweets are instances the classifier has never seen before, so they are a good way to see how the classifier will behave on data it hasn't seen before. However, we still know the labels of the test tweets, so we can measure the accuracy.\n",
    "\n",
    "For this problem, we will use what are called \"bag of words\" features, which are commonly used when doing classification with text. Each feature is a word, and the value of a feature for a particular tweet is number of times the word appears in the tweet (with value $0$ if the word does not appear in the tweet).\n",
    "\n",
    "A note on labels: **If `Y_train` or `Y_test` are 1 this means the tweet refers to a real disaster; if the values are 0, it means the tweet does not refer to a real disaster** \n",
    "\n",
    "Run the block of code below to load the data. You don't need to do anything yet. Move on to \"Problem 1\" next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "Y_train = df_train[\"target\"]\n",
    "text_train = df_train[\"text\"]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(text_train)\n",
    "feature_names = np.asarray(vec.get_feature_names())\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "Y_test = df_test[\"target\"]\n",
    "text_test = df_test[\"text\"]\n",
    "\n",
    "X_test = vec.transform(text_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Understand the data [3 points]\n",
    "\n",
    "Before doing anything else, take time to understand the code above.\n",
    "\n",
    "The variables `df_train` and `df_test` are dataframes that store the training (and testing) datasets, which are contained in comma-separated files where the first column is the label and the second column is the text of the tweet.\n",
    "\n",
    "The [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class converts the raw text into a bag-of-words into a feature vector representation that `sklearn` can use.\n",
    "\n",
    "You should print out the values of the variables and write any other code needed to answer the following questions.\n",
    "\n",
    "#### Deliverable 1.1\n",
    "\n",
    "How many training instances are in the dataset? How many test instances?\n",
    "\n",
    "[your answer here]\n",
    "\n",
    "#### Deliverable 1.2\n",
    "\n",
    "How many features are in the training data?\n",
    "\n",
    "[your answer here]\n",
    "\n",
    "#### Deliverable 1.3\n",
    "\n",
    "What is the distribution of labels in the training data? That is, what percentage of instances are about actual disasters?\n",
    "\n",
    "[your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Perceptron [3 points]\n",
    "\n",
    "The code below trains an [`SGDClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) using the perceptron loss, then it measures the accuracy of the classifier on the test data, using `sklearn`'s [`accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function. \n",
    "\n",
    "The `fit` function trains the classifier. The feature weights are stored in the `coef_` variable after training. The `predict` function of the trained `SGDClassifier` outputs the predicted label for a given instance or list of instances.\n",
    "\n",
    "Additionally, this code displays the features and their weights in sorted order, which you may want to examine to understand what the classifier is learning. In general, in binary classification, the 0 class is considered the \"negative\" class.\n",
    "\n",
    "There are 3 keyword arguments that have been added to the code below. It is important you keep the same values of these arguments whenever you create an `SGDClassifier` instance in this assignment so that you get consistent results. They are:\n",
    "\n",
    "- `max_iter` is one of the stopping criteria, which is the maximum number of iterations/epochs the algorithm will run for.\n",
    "\n",
    "- `tol` is the other stopping criterion, which is how small the difference between the current loss and previous loss should be before stopping.\n",
    "\n",
    "- `random_state` is a seed for pseudorandom number generation. The algorithm uses randomness in the way the training data are sorted, which will affect the solution that is learned, and even the accuracy of that solution.\n",
    "\n",
    "Note: *Wait a minute $-$ in class we learned that the loss function is convex, so the algorithm will find the same minimum regardless of how it is trained. Why is there random variation in the output? The reason is that even though there is only one minimum value of the loss, there may be different weights that result in the same loss, so randomness is a matter of tie-breaking. What's more, while different weights may have the same loss, they could lead to different classification accuracies, because the loss function is not the same as accuracy. (Unless accuracy was your loss function... which is possible, but uncommon because it turns out to be a difficult function to optimize.)\n",
    "Note that different computers may still give different answers, despite keeping these settings the same, because of how pseudorandom numbers are generated with different operating systems and Python environments.*\n",
    "\n",
    "To begin, run the code in the cell below without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SGD iterations: 35\n",
      "Training accuracy: 0.987908\n",
      "Testing accuracy: 0.781648\n",
      "\n",
      "Feature weights:\n",
      "\n",
      " - lowest\n",
      "\t zy3hpdjnwg: -0.7900\n",
      "\t qzlpfhpwdo: -0.6970\n",
      "\t better: -0.5112\n",
      "\t f7wqpcekg2: -0.5112\n",
      "\t sun: -0.5112\n",
      "\n",
      " - highest\n",
      "\t storm: 0.8829\n",
      "\t sunburned: 0.9294\n",
      "\t hurricane: 0.9294\n",
      "\t massacre: 1.0688\n",
      "\t earthquake: 1.2547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "classifier = SGDClassifier(loss='perceptron', max_iter=1000, tol=1.0e-12, random_state=123, eta0=100)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Number of SGD iterations: %d\" % classifier.n_iter_)\n",
    "print(\"Training accuracy: %0.6f\" % accuracy_score(Y_train, classifier.predict(X_train)))\n",
    "print(\"Testing accuracy: %0.6f\" % accuracy_score(Y_test, classifier.predict(X_test)))\n",
    "\n",
    "print(\"\\nFeature weights:\")\n",
    "args = np.argsort(classifier.coef_[0])\n",
    "\n",
    "print(\"\\n - lowest\")\n",
    "for a in args[0:5]:\n",
    "    print(\"\\t %s: %0.4f\" % (feature_names[a], classifier.coef_[0][a]))\n",
    "   \n",
    "print(\"\\n - highest\")\n",
    "for a in args[-5:]:\n",
    "    print(\"\\t %s: %0.4f\" % (feature_names[a], classifier.coef_[0][a]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 2.1\n",
    "\n",
    "Based on the training accuracy, do you conclude that the data are (mostly) linearly separable? Why or why not?\n",
    "\n",
    "[your answer here]\n",
    "\n",
    "#### Deliverable 2.2\n",
    "\n",
    "Which feature most increases the likelihood that the tweet does not refer to a real disaster, and which feature most increases the likelihood that the tweet refers to a real disaster? \n",
    "\n",
    "[your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 2.3 \n",
    "One technique for improving the resulting model with perceptron is to take an average of the weight vectors learned at different iterations of the algorithm, rather than only using the final weights that minimize the loss. That is, calculate $\\bar{\\mathbf{w}} = \\sum_{t=1}^T \\mathbf{w}^{(t)}$ where $\\mathbf{w}^{(t)}$ is the weight vector at iteration $t$ of the algorithm and $T$ is the number of iterations, and then use $\\bar{\\mathbf{w}}$ when making classifications on new data.\n",
    "\n",
    "To use this technique in your classifier, add the keyword argument `average=True` to the `SGDClassifier` function. Try it now using the cells below.\n",
    "\n",
    "Compare the initial training/test accuracies to the training/test accuracies after doing averaging. What happens? Why do you think averaging the weights from different iterations has this effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Logistic regression [4 points]\n",
    "\n",
    "For this problem, create a new `SGDClassifier`, this time setting the `loss` argument to `'log'`, which will train a logistic regression classifier. Set `average=False` for the remaining problems.\n",
    "\n",
    "Once you have trained the classifier, you can use the `predict` function to get the classifications, as with perceptron. Additionally, logistic regression provides probabilities for the predictions. You can get the probabilities by calling the `predict_proba` function. This will give a list of two numbers; the first is the probability that the class is $0$ and the second is the probability that the class is $1$.\n",
    "\n",
    "\n",
    "For the first task, add the keyword argument `alpha` to the `SGDClassifier` function. This is the regularization strength, called $\\lambda$ in lecture. If you don't specify `alpha`, it defaults to $0.0001$. Experiment with other values and see how this affects the outcome.\n",
    "\n",
    "#### Deliverable 3.1: \n",
    "\n",
    "Calculate the training and testing accuracy when `alpha` is one of $[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]$. Create a plot where the x-axis is `alpha` and the y-axis is accuracy, with two lines (one for training and one for testing). You can borrow the code from HW1 for generating plots in Python. Use [a log scale for the x-axis](https://matplotlib.org/examples/pylab_examples/log_demo.html) so that the `alpha` values are spaced evenly.\n",
    "\n",
    "[your solution should be plotted below]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.808660\n",
      "Testing accuracy: 0.773610\n"
     ]
    }
   ],
   "source": [
    "# starter code\n",
    "classifier = SGDClassifier(loss='log', max_iter=1000, alpha=.01, tol=1.0e-12, random_state=123, eta0=100, average=False)\n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"Training accuracy: %0.6f\" % accuracy_score(Y_train, classifier.predict(X_train)))\n",
    "print(\"Testing accuracy: %0.6f\" % accuracy_score(Y_test, classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.2\n",
    "\n",
    "Examine the classifier probabilities using the `predict_proba` function when training with different values of `alpha`. What do you observe? How does `alpha` affect the prediction probabilities, and why do you think this happens?\n",
    "\n",
    "[your answer here]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.3: \n",
    "\n",
    "Now remove the `alpha` argument so that it goes back to the default value. We'll now look at the effect of the learning rate. By default, `sklearn` uses an \"optimal\" learning rate based on some heuristics that work well for many problems. However, it can be good to see how the learning rate can affect the algorithm.\n",
    "\n",
    "For this task, add the keyword argument `learning_rate` to the `SGDClassifier` function and set the value to `invscaling`. This defines the learning rate at iteration $t$ as: $\\eta_t = \\frac{\\eta_0}{t^a}$, where $\\eta_0$ and $a$ are both arguments you have to define in the `SGDClassifier` function, called `eta0` and `power_t`, respectively. Experiment with different values of `eta0` and `power_t` and see how they affect the number of iterations it takes the algorithm to converge. You will often find that it will not finish within the maximum of $1000$ iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the table below with the number of iterations for values of `eta0` in $[10.0, 100.0, 1000.0, 10000.0]$ and values of `power_t` in $[0.5, 1.0, 2.0]$. You may find it easier to write python code that can output the markdown for the table, but if you do that place the output here. If it does not converge within the maximum number of iterations (set to $1000$ by `max_iter`), record $1000$ as the number of iterations. You will need to read the documentation for this class to learn how to recover the actual number of iterations before reaching the stopping criterion.\n",
    "\n",
    "| `eta0`   | `power_t` | # Iterations |\n",
    "|:----------|:-:|:------------:|\n",
    "| $10.0$    | $0.5$     |              |\n",
    "| $10.0$    | $1.0$     |              |\n",
    "| $10.0$    | $2.0$     |              |\n",
    "| $100.0$   | $0.5$     |              |\n",
    "| $100.0$   | $1.0$     |              |\n",
    "| $100.0$   | $2.0$     |              |\n",
    "| $1000.0$  | $0.5$     |              |\n",
    "| $1000.0$  | $1.0$     |              |\n",
    "| $1000.0$  | $2.0$     |              |\n",
    "| $10000.0$ | $0.5$     |              |\n",
    "| $10000.0$ | $1.0$     |              |\n",
    "| $10000.0$ | $2.0$     |              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.4\n",
    "\n",
    "Describe how `eta0` and `power_t` affect the learning rate based on the formula (e.g., if you increase `power_t`, what will this do to the learning rate?), and connect this to what you observe in the table above.\n",
    "\n",
    "[your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove the `learning_rate`, `eta0`, and `power_t` arguments so that the learning rate returns to the default setting. For this final task, we will experiment with how high the probabiity must be before an instance is classified as positive.\n",
    "\n",
    "The code below includes a function called `threshold` which takes as input the classification probabilities of the data (called `probs`, which is given by the function `predict_proba`) and a threshold (called `tau`, a scalar that should be a value between $0$ and $1$). It will classify each instance as $1$ if the probability of being $1$ is greater than `tau`, otherwise it will classify the instance as $0$. Note that if you set `tau` to $0.5$, the `threshold` function should give you exactly the same output as the classifier `predict` function.\n",
    "\n",
    "You should find that increasing the threshold causes the accuracy to drop. This makes sense, because you are classifying some things as 0 even though it's more probable that they are 1. So why do this? Suppose you care more about accurately identifying tweets about natural disasters than missing tweets about disasters (e.g. maybe you forward these tweets to first responders.) You thus want to be confident that when you classify a tweet as 1 that it really is 1.\n",
    "\n",
    "There is a metric called _precision_ which measures something like accuracy but for one specific class. Whereas accuracy is the percentage of tweets that were correctly classified, the precision of 1 would be the percentage of tweets classified as 1 that were correctly classified. (In other words, the number of tweets classified as 1 whose correct label was 1, divided by the number of tweets classified as 1.)\n",
    "\n",
    "You can use the [`precision_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) function from `sklearn` to calculate the precision. It works much like the `accuracy_score` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.5\n",
    "\n",
    "Calculate the testing precision when the value of `tau` for thresholding is one of $[0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]$. Create a plot where the x-axis is `tau` and the y-axis is precision.\n",
    "\n",
    "[your solution should be plotted below]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', random_state=123, tol=1e-12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this function for deliverable 3.5\n",
    "def threshold(probs, tau):\n",
    "    return np.where(probs[:,1] > tau, 1, 0)\n",
    "\n",
    "# your logistic regression code here\n",
    "\n",
    "classifier = SGDClassifier(loss='log', max_iter=1000, tol=1.0e-12, random_state=123)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "probs = classifier.predict_proba()\n",
    "\n",
    "preds = threshold(probs, tau=.9)\n",
    "\n",
    "precision_score(preds, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 3.6\n",
    "\n",
    "Describe what you observe with thresholding (e.g., what happens to precision as the threshold increases?), and explain why you think this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Sparse learning [5604: 5 points; 4604: +3 EC points]\n",
    "\n",
    "Add the `penalty` argument to `SGDClassifier` and set the value to `'l1'`, which tells the algorithm to use L1 regularization instead of the default L2. Recall from lecture that L1 regularization encourages weights to stay at exactly $0$, resulting in a more \"sparse\" model than L2. You should see this effect if you examine the values of `classifier.coef_`.\n",
    "\n",
    "#### Deliverable 4.1: \n",
    "\n",
    "Write a function to calculate the number of features whose weights are nonzero when using L1 regularization. Calculate the number of nonzero feature weights when `alpha` is one of $[0.00001, 0.0001, 0.001, 0.01, 0.1]$. Create a plot where the x-axis is `alpha` and the y-axis is the number of nonzero weights, using a log scale for the x-axis.\n",
    "\n",
    "[your solution should be plotted below]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Briefly explain your plot in a few sentences. What happens as you increase `alpha`; does that make sense?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
