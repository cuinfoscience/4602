{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "- In this notebook we will get practice using cross validation to perform hyperparameter tuning. \n",
    "\n",
    "- Sklearn [implements sklearn for you](https://scikit-learn.org/stable/modules/cross_validation.html) and is totally fine to use the built-in implementation for future homeworks. \n",
    "\n",
    "- However, you will understand this concept much better if you practice implmenting it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# configure matplotlib to show plots in the notebook itself\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "In this notebook, we will be using the [Pima Indians Diabetes Dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database). The data consists of patient records with a number of features, along with a binary label indicating if the patient has diabetes or does not have diabetes. Note that the \"all patients\" in the dataset are \"are females at least 21 years old of Pima Indian heritage.\" Note that the `outcome` variable records if a patient does or does not have diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv') #Load the dataset\n",
    "\n",
    "# Let's go ahead and start with a two-dimensional dataset to build intuitions\n",
    "X = df[['Glucose', 'BloodPressure']]\n",
    "Y = df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break the data into training and test\n",
    "\n",
    "- Divide the dataset into training and testing. Use the last 100\n",
    "instances for test and the rest for training. Pandas [iloc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html) is helpful for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer cell. Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive approach\n",
    "\n",
    "Let's start off by naively tuning to find the \"best\" $K$ using a naive grid search. You should loop over all values of K from 2 to 75 and find the value of $K$ that gets the highest accuracy on the training set. This process is likely familiar from other assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the classifier on all neighbors from K=2 to K=75\n",
    "accuracy_record = []\n",
    "neighbors = range(2, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate plot to pick a K value\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "plt.title('k-NN Varying number of neighbors')\n",
    "plt.plot(neighbors, accuracy_record, label='Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pick a value of K based on the plot, and predict the accuracy on the test set \n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reflection \n",
    "\n",
    "What value of $K$ did you pick? Was your accuracy on the test set higher or lower than you expected? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A better approach with cross validation\n",
    "\n",
    "Now we will try that again using cross validation. Cross validation is important and useful! Coding it yourself will help you really understand the concept. So we will build up to an implementation in the rest of the notebook. Hopefully, it will get us to better test set accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to divide the dataset into $K$ equal folds. For each fold, we will need: \n",
    "\n",
    "- `X_held_out`: a matrix of held out training data (i.e. a pseudo test set)\n",
    "- `Y_held_out`: a vector of held out labels\n",
    "\n",
    "- `X_remainder`: training data not included in the held out set\n",
    "- `Y_remainder`: labels for training data not included in the held out set\n",
    "\n",
    "Let's start off by writing a function that takes the training set as input, along with the indexes of the held out data, and returns a dictionary with the four fields listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fold(X_train, Y_train, indexes_of_held_out_data):\n",
    "    '''\n",
    "    Take the training data and return a dictionary with four keys:\n",
    "        \"X_held_out\", \"Y_held_out\", \"X_remainder\", \"Y_remainder\"\n",
    "    Links: \n",
    "        - https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-basics\n",
    "        - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
    "    '''\n",
    "    return {\"X_held_out\": None, \n",
    "            \"Y_held_out\": None,\n",
    "            \"X_remainder\": None,\n",
    "            \"Y_remainder\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the make_fold function to complete the make_folds function, which divides the data into $K$ folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folds(_X_train, _Y_train, K):\n",
    "    '''\n",
    "    \n",
    "    Divide the dataset into K equal folds using the make_fold function above\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): A numpy matrix of N rows and J features\n",
    "        Y (np.ndarray): A numpy array of N rows, with binary labels\n",
    "        K (int): the number of folds\n",
    "\n",
    "    Returns:\n",
    "        Return a dictionary with keys 1 thru K. Each key maps to an equal-sized subset of the data. The subsets \n",
    "        should not overlap\n",
    "                              {1: {\"X_train\": fold_1_X_train, \"Y_train\": fold_1_Y_train}, \n",
    "                               2: {\"X_train\": fold_2_X_train, \"Y_train\": fold_2_Y_train}  \n",
    "                               ... \n",
    "                               }\n",
    "\n",
    "        In some cases, the sizes of the folds will differ by 1 \n",
    "        (e.g. if N=16 and K=3, you should have folds of sizes 5, 5 and 6)\n",
    "    '''\n",
    "    fold_size = int(len(_X_train)/K)\n",
    "    N = len(_X_train)\n",
    "    ou = {}\n",
    "    for f in range(K):\n",
    "        select_these = None # TODO: fill in with indexes to select\n",
    "        ou[f] = make_fold(_X_train, _Y_train, select_these)\n",
    "    return ou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform cross valdation! \n",
    "\n",
    "We are now ready to perform cross validation. In the code below, for each $K$:\n",
    "1. Use your make_folds function to divide the training data into $K$ folds. \n",
    "2. Then train the data on the remaining data and \"test\" it on the held out validation data. Test is in quotes here because remember we are just dividing up the training set.\n",
    "3. Average the performance over each of the folds to get the average held out performance.\n",
    "4. Compute the training performance for each $K$\n",
    "\n",
    "Based on the average held out performance, pick the best $K$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your cross validation code here\n",
    "\n",
    "\n",
    "# make folds. These can stay the same for all K\n",
    "\n",
    "\n",
    "# loop over values of K\n",
    "for k in range(3, 75): \n",
    "    \n",
    "    accuracies = []\n",
    "    knn = None # Instantiate a KNN classifier examining K neighbors\n",
    "\n",
    "    for fold in folds:\n",
    "        \n",
    "        # train the classifier on the remaining data\n",
    "        # test on the held out data\n",
    "        # Record the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best K?\n",
    "\n",
    "Make another plot showing validation accuracy for different values of $K$, and the trianing accuracy of $K$. This is sometimes called a [validation curve](https://scikit-learn.org/stable/modules/learning_curve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "\n",
    "Based on your plot, which values of $K$ might be underfitting? Which values of $K$ might be overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy\n",
    "\n",
    "1. Which $K$ seems to do best on validation data? \n",
    "2. Using this value of $K$, compute your test accuracy again, this time with your best value of $K$. What do you observe? (Remember, normally, you would compute test accuracy only once because you don't peek at the test data. But this notebook is just for practice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
